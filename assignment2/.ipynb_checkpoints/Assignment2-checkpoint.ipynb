{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>330</td>\n",
       "      <td>115</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>308</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>302</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>325</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>328</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>307</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>311</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>314</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>317</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>319</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>303</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>312</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>325</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>328</td>\n",
       "      <td>116</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>334</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>340</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>322</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>298</td>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>295</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>310</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>336</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>321</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>315</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>304</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>297</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>290</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>303</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>311</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>319</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>340</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>335</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>302</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>307</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>296</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>320</td>\n",
       "      <td>108</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>314</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>318</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>326</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>317</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>329</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "5          330          115                  5  4.5   3.0  9.34         1   \n",
       "6          321          109                  3  3.0   4.0  8.20         1   \n",
       "7          308          101                  2  3.0   4.0  7.90         0   \n",
       "8          302          102                  1  2.0   1.5  8.00         0   \n",
       "9          323          108                  3  3.5   3.0  8.60         0   \n",
       "10         325          106                  3  3.5   4.0  8.40         1   \n",
       "11         327          111                  4  4.0   4.5  9.00         1   \n",
       "12         328          112                  4  4.0   4.5  9.10         1   \n",
       "13         307          109                  3  4.0   3.0  8.00         1   \n",
       "14         311          104                  3  3.5   2.0  8.20         1   \n",
       "15         314          105                  3  3.5   2.5  8.30         0   \n",
       "16         317          107                  3  4.0   3.0  8.70         0   \n",
       "17         319          106                  3  4.0   3.0  8.00         1   \n",
       "18         318          110                  3  4.0   3.0  8.80         0   \n",
       "19         303          102                  3  3.5   3.0  8.50         0   \n",
       "20         312          107                  3  3.0   2.0  7.90         1   \n",
       "21         325          114                  4  3.0   2.0  8.40         0   \n",
       "22         328          116                  5  5.0   5.0  9.50         1   \n",
       "23         334          119                  5  5.0   4.5  9.70         1   \n",
       "24         336          119                  5  4.0   3.5  9.80         1   \n",
       "25         340          120                  5  4.5   4.5  9.60         1   \n",
       "26         322          109                  5  4.5   3.5  8.80         0   \n",
       "27         298           98                  2  1.5   2.5  7.50         1   \n",
       "28         295           93                  1  2.0   2.0  7.20         0   \n",
       "29         310           99                  2  1.5   2.0  7.30         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "370        310          103                  2  2.5   2.5  8.24         0   \n",
       "371        324          110                  3  3.5   3.0  9.22         1   \n",
       "372        336          119                  4  4.5   4.0  9.62         1   \n",
       "373        321          109                  3  3.0   3.0  8.54         1   \n",
       "374        315          105                  2  2.0   2.5  7.65         0   \n",
       "375        304          101                  2  2.0   2.5  7.66         0   \n",
       "376        297           96                  2  2.5   2.0  7.43         0   \n",
       "377        290          100                  1  1.5   2.0  7.56         0   \n",
       "378        303           98                  1  2.0   2.5  7.65         0   \n",
       "379        311           99                  1  2.5   3.0  8.43         1   \n",
       "380        322          104                  3  3.5   4.0  8.84         1   \n",
       "381        319          105                  3  3.0   3.5  8.67         1   \n",
       "382        324          110                  4  4.5   4.0  9.15         1   \n",
       "383        300          100                  3  3.0   3.5  8.26         0   \n",
       "384        340          113                  4  5.0   5.0  9.74         1   \n",
       "385        335          117                  5  5.0   5.0  9.82         1   \n",
       "386        302          101                  2  2.5   3.5  7.96         0   \n",
       "387        307          105                  2  2.0   3.5  8.10         0   \n",
       "388        296           97                  2  1.5   2.0  7.80         0   \n",
       "389        320          108                  3  3.5   4.0  8.44         1   \n",
       "390        314          102                  2  2.0   2.5  8.24         0   \n",
       "391        318          106                  3  2.0   3.0  8.65         0   \n",
       "392        326          112                  4  4.0   3.5  9.12         1   \n",
       "393        317          104                  2  3.0   3.0  8.76         0   \n",
       "394        329          111                  4  4.5   4.0  9.23         1   \n",
       "395        324          110                  3  3.5   3.5  9.04         1   \n",
       "396        325          107                  3  3.0   3.5  9.11         1   \n",
       "397        330          116                  4  5.0   4.5  9.45         1   \n",
       "398        312          103                  3  3.5   4.0  8.78         0   \n",
       "399        333          117                  4  5.0   4.0  9.66         1   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "5                0.90  \n",
       "6                0.75  \n",
       "7                0.68  \n",
       "8                0.50  \n",
       "9                0.45  \n",
       "10               0.52  \n",
       "11               0.84  \n",
       "12               0.78  \n",
       "13               0.62  \n",
       "14               0.61  \n",
       "15               0.54  \n",
       "16               0.66  \n",
       "17               0.65  \n",
       "18               0.63  \n",
       "19               0.62  \n",
       "20               0.64  \n",
       "21               0.70  \n",
       "22               0.94  \n",
       "23               0.95  \n",
       "24               0.97  \n",
       "25               0.94  \n",
       "26               0.76  \n",
       "27               0.44  \n",
       "28               0.46  \n",
       "29               0.54  \n",
       "..                ...  \n",
       "370              0.72  \n",
       "371              0.89  \n",
       "372              0.95  \n",
       "373              0.79  \n",
       "374              0.39  \n",
       "375              0.38  \n",
       "376              0.34  \n",
       "377              0.47  \n",
       "378              0.56  \n",
       "379              0.71  \n",
       "380              0.78  \n",
       "381              0.73  \n",
       "382              0.82  \n",
       "383              0.62  \n",
       "384              0.96  \n",
       "385              0.96  \n",
       "386              0.46  \n",
       "387              0.53  \n",
       "388              0.49  \n",
       "389              0.76  \n",
       "390              0.64  \n",
       "391              0.71  \n",
       "392              0.84  \n",
       "393              0.77  \n",
       "394              0.89  \n",
       "395              0.82  \n",
       "396              0.84  \n",
       "397              0.91  \n",
       "398              0.67  \n",
       "399              0.95  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>0.835977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.791594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.669889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.873289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.802610</td>\n",
       "      <td>0.791594</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.669889</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
       "GRE Score           1.000000     0.835977           0.668976  0.612831   \n",
       "TOEFL Score         0.835977     1.000000           0.695590  0.657981   \n",
       "University Rating   0.668976     0.695590           1.000000  0.734523   \n",
       "SOP                 0.612831     0.657981           0.734523  1.000000   \n",
       "LOR                 0.557555     0.567721           0.660123  0.729593   \n",
       "CGPA                0.833060     0.828417           0.746479  0.718144   \n",
       "Research            0.580391     0.489858           0.447783  0.444029   \n",
       "Chance of Admit     0.802610     0.791594           0.711250  0.675732   \n",
       "\n",
       "                       LOR       CGPA  Research  Chance of Admit   \n",
       "GRE Score          0.557555  0.833060  0.580391          0.802610  \n",
       "TOEFL Score        0.567721  0.828417  0.489858          0.791594  \n",
       "University Rating  0.660123  0.746479  0.447783          0.711250  \n",
       "SOP                0.729593  0.718144  0.444029          0.675732  \n",
       "LOR                1.000000  0.670211  0.396859          0.669889  \n",
       "CGPA               0.670211  1.000000  0.521654          0.873289  \n",
       "Research           0.396859  0.521654  1.000000          0.553202  \n",
       "Chance of Admit    0.669889  0.873289  0.553202          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 72 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cols1=[\"Chance of Admit \",\"GRE Score\",\"TOEFL Score\",\"University Rating\",\"SOP\",\"LOR \",\"CGPA\",\"Research\"]\n",
    "sns.pairplot(df[cols1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X: <class 'numpy.ndarray'>\n",
      "Shape of X: (400, 7)\n",
      "Type of y: <class 'numpy.ndarray'>\n",
      "Shape of y: (400,)\n"
     ]
    }
   ],
   "source": [
    "X_df=df.iloc[:, :-1]\n",
    "y_df=df.iloc[:,-1]\n",
    "X=X_df.values\n",
    "y=y_df.values\n",
    "print(\"Type of X:\", type(X))\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Type of y:\", type(y))\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_and_valid shape: (320, 7)\n",
      "y_train_and_valid shape: (320,)\n",
      "=============================\n",
      "X_test shape: (80, 7)\n",
      "y_test shape: (80,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_and_valid, X_test, y_train_and_valid, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "print(\"X_train_and_valid shape:\", X_train_and_valid.shape)\n",
    "print(\"y_train_and_valid shape:\", y_train_and_valid.shape)\n",
    "print(\"=============================\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (256, 7)\n",
      "y_train shape: (256,)\n",
      "=============================\n",
      "X_valid shape: (64, 7)\n",
      "y_valid shape: (64,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_and_valid, y_train_and_valid, test_size=0.2, random_state=0)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"=============================\")\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "estimators_settings=list(range(64,129))\n",
    "max_feature_settings = list(range(2, 8))\n",
    "pruning_settings=list(range(2,11))\n",
    "data_dict=dict()\n",
    "\n",
    "for n in estimators_settings:\n",
    "    feature_dict=dict()\n",
    "    for f in max_feature_settings:\n",
    "        p1_dict=dict()\n",
    "        for p1 in pruning_settings:\n",
    "            training_r2=[]\n",
    "            training_rmse=[]\n",
    "            valid_r2=[]\n",
    "            valid_rmse=[]\n",
    "            for p2 in pruning_settings:\n",
    "                    # build the model\n",
    "                    RFR=RandomForestRegressor(n_estimators=n, \n",
    "                                              max_features=f,\n",
    "                                              max_depth=p1,\n",
    "                                              max_leaf_nodes=None,\n",
    "                                              min_samples_leaf=p2,\n",
    "                                              n_jobs=3,\n",
    "                                              random_state=0)\n",
    "                    RFR.fit(X_train, y_train)\n",
    "                    \n",
    "                    y_train_hat = RFR.predict(X_train)\n",
    "                    training_rmse.append(mean_squared_error(y_train, y_train_hat)**0.5)\n",
    "                    training_r2.append(r2_score(y_train, y_train_hat))\n",
    "                    \n",
    "                    y_valid_hat = RFR.predict(X_valid)\n",
    "                    valid_rmse.append(mean_squared_error(y_valid, y_valid_hat)**0.5)\n",
    "                    valid_r2.append(r2_score(y_valid, y_valid_hat))\n",
    "            p1_dict[p1]=dict(TRMSE=training_rmse, VRMSE=valid_rmse, TR2=training_r2, VR2=valid_r2)\n",
    "        feature_dict[f]=p1_dict\n",
    "    data_dict[n]=feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>max feature</th>\n",
       "      <th>max depth</th>\n",
       "      <th>min samlples leaf</th>\n",
       "      <th>training rmse</th>\n",
       "      <th>valid rmse</th>\n",
       "      <th>training r2</th>\n",
       "      <th>valid r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>0.788244</td>\n",
       "      <td>0.708824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.067308</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>0.788244</td>\n",
       "      <td>0.708824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.067300</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.788290</td>\n",
       "      <td>0.709490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.067352</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.787965</td>\n",
       "      <td>0.709128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.072836</td>\n",
       "      <td>0.787662</td>\n",
       "      <td>0.708259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0.072902</td>\n",
       "      <td>0.787544</td>\n",
       "      <td>0.707725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.067443</td>\n",
       "      <td>0.072866</td>\n",
       "      <td>0.787391</td>\n",
       "      <td>0.708016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.067446</td>\n",
       "      <td>0.073013</td>\n",
       "      <td>0.787375</td>\n",
       "      <td>0.706838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.067475</td>\n",
       "      <td>0.073175</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.705534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.837003</td>\n",
       "      <td>0.732863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.059180</td>\n",
       "      <td>0.069639</td>\n",
       "      <td>0.836295</td>\n",
       "      <td>0.733303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.059454</td>\n",
       "      <td>0.070060</td>\n",
       "      <td>0.834779</td>\n",
       "      <td>0.730070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.059719</td>\n",
       "      <td>0.070040</td>\n",
       "      <td>0.833304</td>\n",
       "      <td>0.730226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.059818</td>\n",
       "      <td>0.070028</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0.730313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.059738</td>\n",
       "      <td>0.070315</td>\n",
       "      <td>0.833197</td>\n",
       "      <td>0.728103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.059910</td>\n",
       "      <td>0.070538</td>\n",
       "      <td>0.832233</td>\n",
       "      <td>0.726377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.060033</td>\n",
       "      <td>0.070682</td>\n",
       "      <td>0.831544</td>\n",
       "      <td>0.725260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.060528</td>\n",
       "      <td>0.070875</td>\n",
       "      <td>0.828753</td>\n",
       "      <td>0.723750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053377</td>\n",
       "      <td>0.070646</td>\n",
       "      <td>0.866826</td>\n",
       "      <td>0.725535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.070884</td>\n",
       "      <td>0.863236</td>\n",
       "      <td>0.723680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.054524</td>\n",
       "      <td>0.070585</td>\n",
       "      <td>0.861043</td>\n",
       "      <td>0.726010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.070402</td>\n",
       "      <td>0.855852</td>\n",
       "      <td>0.727428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056580</td>\n",
       "      <td>0.071020</td>\n",
       "      <td>0.850365</td>\n",
       "      <td>0.722619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>0.070669</td>\n",
       "      <td>0.849824</td>\n",
       "      <td>0.725360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.057660</td>\n",
       "      <td>0.070907</td>\n",
       "      <td>0.844596</td>\n",
       "      <td>0.723506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058177</td>\n",
       "      <td>0.071008</td>\n",
       "      <td>0.841802</td>\n",
       "      <td>0.722716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>0.071181</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.721362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.048695</td>\n",
       "      <td>0.070342</td>\n",
       "      <td>0.889167</td>\n",
       "      <td>0.727896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050285</td>\n",
       "      <td>0.071805</td>\n",
       "      <td>0.881811</td>\n",
       "      <td>0.716453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.051808</td>\n",
       "      <td>0.071470</td>\n",
       "      <td>0.874539</td>\n",
       "      <td>0.719099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31560</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.051345</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.876776</td>\n",
       "      <td>0.619177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31561</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.052236</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>0.623050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31562</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.082054</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.629735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31563</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034252</td>\n",
       "      <td>0.082036</td>\n",
       "      <td>0.945162</td>\n",
       "      <td>0.629902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31564</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040190</td>\n",
       "      <td>0.083127</td>\n",
       "      <td>0.924503</td>\n",
       "      <td>0.619992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31565</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044427</td>\n",
       "      <td>0.083680</td>\n",
       "      <td>0.907745</td>\n",
       "      <td>0.614918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31566</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.897203</td>\n",
       "      <td>0.619849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31567</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.083348</td>\n",
       "      <td>0.888316</td>\n",
       "      <td>0.617969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31568</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>0.083236</td>\n",
       "      <td>0.881696</td>\n",
       "      <td>0.618994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31569</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.876821</td>\n",
       "      <td>0.619145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31570</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.052236</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>0.623050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31571</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.082054</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.629735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31572</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>0.082415</td>\n",
       "      <td>0.947636</td>\n",
       "      <td>0.626470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31573</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>0.925149</td>\n",
       "      <td>0.618825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31574</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044354</td>\n",
       "      <td>0.083723</td>\n",
       "      <td>0.908047</td>\n",
       "      <td>0.614519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31575</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.083121</td>\n",
       "      <td>0.897295</td>\n",
       "      <td>0.620046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31576</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048880</td>\n",
       "      <td>0.083346</td>\n",
       "      <td>0.888323</td>\n",
       "      <td>0.617987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31577</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>0.083236</td>\n",
       "      <td>0.881696</td>\n",
       "      <td>0.618994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31578</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.876821</td>\n",
       "      <td>0.619145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31579</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.052236</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>0.623050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31580</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.082054</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.629735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31581</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.082349</td>\n",
       "      <td>0.948478</td>\n",
       "      <td>0.627070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.039977</td>\n",
       "      <td>0.083249</td>\n",
       "      <td>0.925300</td>\n",
       "      <td>0.618869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.083724</td>\n",
       "      <td>0.908091</td>\n",
       "      <td>0.614509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.083121</td>\n",
       "      <td>0.897295</td>\n",
       "      <td>0.620046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048880</td>\n",
       "      <td>0.083346</td>\n",
       "      <td>0.888323</td>\n",
       "      <td>0.617987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31586</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>0.083236</td>\n",
       "      <td>0.881696</td>\n",
       "      <td>0.618994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31587</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.051335</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.876821</td>\n",
       "      <td>0.619145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31588</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.052236</td>\n",
       "      <td>0.082792</td>\n",
       "      <td>0.872460</td>\n",
       "      <td>0.623050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31589</th>\n",
       "      <td>128</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.082054</td>\n",
       "      <td>0.868291</td>\n",
       "      <td>0.629735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31590 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       estimators  max feature  max depth  min samlples leaf  training rmse  \\\n",
       "0              64            2          2                  2       0.067308   \n",
       "1              64            2          2                  3       0.067308   \n",
       "2              64            2          2                  4       0.067300   \n",
       "3              64            2          2                  5       0.067352   \n",
       "4              64            2          2                  6       0.067400   \n",
       "5              64            2          2                  7       0.067419   \n",
       "6              64            2          2                  8       0.067443   \n",
       "7              64            2          2                  9       0.067446   \n",
       "8              64            2          2                 10       0.067475   \n",
       "9              64            2          3                  2       0.059052   \n",
       "10             64            2          3                  3       0.059180   \n",
       "11             64            2          3                  4       0.059454   \n",
       "12             64            2          3                  5       0.059719   \n",
       "13             64            2          3                  6       0.059818   \n",
       "14             64            2          3                  7       0.059738   \n",
       "15             64            2          3                  8       0.059910   \n",
       "16             64            2          3                  9       0.060033   \n",
       "17             64            2          3                 10       0.060528   \n",
       "18             64            2          4                  2       0.053377   \n",
       "19             64            2          4                  3       0.054092   \n",
       "20             64            2          4                  4       0.054524   \n",
       "21             64            2          4                  5       0.055533   \n",
       "22             64            2          4                  6       0.056580   \n",
       "23             64            2          4                  7       0.056682   \n",
       "24             64            2          4                  8       0.057660   \n",
       "25             64            2          4                  9       0.058177   \n",
       "26             64            2          4                 10       0.058675   \n",
       "27             64            2          5                  2       0.048695   \n",
       "28             64            2          5                  3       0.050285   \n",
       "29             64            2          5                  4       0.051808   \n",
       "...           ...          ...        ...                ...            ...   \n",
       "31560         128            7          7                  8       0.051345   \n",
       "31561         128            7          7                  9       0.052236   \n",
       "31562         128            7          7                 10       0.053083   \n",
       "31563         128            7          8                  2       0.034252   \n",
       "31564         128            7          8                  3       0.040190   \n",
       "31565         128            7          8                  4       0.044427   \n",
       "31566         128            7          8                  5       0.046896   \n",
       "31567         128            7          8                  6       0.048881   \n",
       "31568         128            7          8                  7       0.050309   \n",
       "31569         128            7          8                  8       0.051335   \n",
       "31570         128            7          8                  9       0.052236   \n",
       "31571         128            7          8                 10       0.053083   \n",
       "31572         128            7          9                  2       0.033471   \n",
       "31573         128            7          9                  3       0.040017   \n",
       "31574         128            7          9                  4       0.044354   \n",
       "31575         128            7          9                  5       0.046875   \n",
       "31576         128            7          9                  6       0.048880   \n",
       "31577         128            7          9                  7       0.050309   \n",
       "31578         128            7          9                  8       0.051335   \n",
       "31579         128            7          9                  9       0.052236   \n",
       "31580         128            7          9                 10       0.053083   \n",
       "31581         128            7         10                  2       0.033200   \n",
       "31582         128            7         10                  3       0.039977   \n",
       "31583         128            7         10                  4       0.044343   \n",
       "31584         128            7         10                  5       0.046875   \n",
       "31585         128            7         10                  6       0.048880   \n",
       "31586         128            7         10                  7       0.050309   \n",
       "31587         128            7         10                  8       0.051335   \n",
       "31588         128            7         10                  9       0.052236   \n",
       "31589         128            7         10                 10       0.053083   \n",
       "\n",
       "       valid rmse  training r2  valid r2  \n",
       "0        0.072765     0.788244  0.708824  \n",
       "1        0.072765     0.788244  0.708824  \n",
       "2        0.072682     0.788290  0.709490  \n",
       "3        0.072727     0.787965  0.709128  \n",
       "4        0.072836     0.787662  0.708259  \n",
       "5        0.072902     0.787544  0.707725  \n",
       "6        0.072866     0.787391  0.708016  \n",
       "7        0.073013     0.787375  0.706838  \n",
       "8        0.073175     0.787191  0.705534  \n",
       "9        0.069697     0.837003  0.732863  \n",
       "10       0.069639     0.836295  0.733303  \n",
       "11       0.070060     0.834779  0.730070  \n",
       "12       0.070040     0.833304  0.730226  \n",
       "13       0.070028     0.832751  0.730313  \n",
       "14       0.070315     0.833197  0.728103  \n",
       "15       0.070538     0.832233  0.726377  \n",
       "16       0.070682     0.831544  0.725260  \n",
       "17       0.070875     0.828753  0.723750  \n",
       "18       0.070646     0.866826  0.725535  \n",
       "19       0.070884     0.863236  0.723680  \n",
       "20       0.070585     0.861043  0.726010  \n",
       "21       0.070402     0.855852  0.727428  \n",
       "22       0.071020     0.850365  0.722619  \n",
       "23       0.070669     0.849824  0.725360  \n",
       "24       0.070907     0.844596  0.723506  \n",
       "25       0.071008     0.841802  0.722716  \n",
       "26       0.071181     0.839080  0.721362  \n",
       "27       0.070342     0.889167  0.727896  \n",
       "28       0.071805     0.881811  0.716453  \n",
       "29       0.071470     0.874539  0.719099  \n",
       "...           ...          ...       ...  \n",
       "31560    0.083216     0.876776  0.619177  \n",
       "31561    0.082792     0.872460  0.623050  \n",
       "31562    0.082054     0.868291  0.629735  \n",
       "31563    0.082036     0.945162  0.629902  \n",
       "31564    0.083127     0.924503  0.619992  \n",
       "31565    0.083680     0.907745  0.614918  \n",
       "31566    0.083142     0.897203  0.619849  \n",
       "31567    0.083348     0.888316  0.617969  \n",
       "31568    0.083236     0.881696  0.618994  \n",
       "31569    0.083219     0.876821  0.619145  \n",
       "31570    0.082792     0.872460  0.623050  \n",
       "31571    0.082054     0.868291  0.629735  \n",
       "31572    0.082415     0.947636  0.626470  \n",
       "31573    0.083254     0.925149  0.618825  \n",
       "31574    0.083723     0.908047  0.614519  \n",
       "31575    0.083121     0.897295  0.620046  \n",
       "31576    0.083346     0.888323  0.617987  \n",
       "31577    0.083236     0.881696  0.618994  \n",
       "31578    0.083219     0.876821  0.619145  \n",
       "31579    0.082792     0.872460  0.623050  \n",
       "31580    0.082054     0.868291  0.629735  \n",
       "31581    0.082349     0.948478  0.627070  \n",
       "31582    0.083249     0.925300  0.618869  \n",
       "31583    0.083724     0.908091  0.614509  \n",
       "31584    0.083121     0.897295  0.620046  \n",
       "31585    0.083346     0.888323  0.617987  \n",
       "31586    0.083236     0.881696  0.618994  \n",
       "31587    0.083219     0.876821  0.619145  \n",
       "31588    0.082792     0.872460  0.623050  \n",
       "31589    0.082054     0.868291  0.629735  \n",
       "\n",
       "[31590 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=dict()\n",
    "\n",
    "\n",
    "for n in estimators_settings:\n",
    "    for f in max_feature_settings:\n",
    "        for p1 in pruning_settings:\n",
    "            for p2 in pruning_settings:\n",
    "                if data.get('estimators'):\n",
    "                    data['estimators'].append(n)\n",
    "                    data['max feature'].append(f)\n",
    "                    data['max depth'].append(p1)\n",
    "                    data['min samlples leaf'].append(p2)\n",
    "\n",
    "                    data['training rmse'].append(data_dict[n][f][p1]['TRMSE'][p2-2])\n",
    "                    data['valid rmse'].append(data_dict[n][f][p1]['VRMSE'][p2-2])\n",
    "                    data['training r2'].append(data_dict[n][f][p1]['TR2'][p2-2])\n",
    "                    data['valid r2'].append(data_dict[n][f][p1]['VR2'][p2-2])\n",
    "                else:\n",
    "                    data['estimators']=[n]\n",
    "                    data['max feature']=[f]\n",
    "                    data['max depth']=[p1]\n",
    "                    data['min samlples leaf']=[p2]\n",
    "\n",
    "                    data['training rmse']=[data_dict[n][f][p1]['TRMSE'][p2-2]]\n",
    "                    data['valid rmse']=[data_dict[n][f][p1]['VRMSE'][p2-2]]\n",
    "                    data['training r2']=[data_dict[n][f][p1]['TR2'][p2-2]]\n",
    "                    data['valid r2']=[data_dict[n][f][p1]['VR2'][p2-2]]\n",
    "\n",
    "df=pd.DataFrame(data, index=list(range(0,len(estimators_settings)*6*9*9)), \n",
    "                columns=['estimators','max feature','max depth','min samlples leaf','training rmse','valid rmse','training r2','valid r2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1range=list(range(1,len(df)+1))\n",
    "# x2range=data[\"estimators\"]\n",
    "# y1range=data[\"training rmse\"]\n",
    "\n",
    "# #training and valid rmse\n",
    "# plt.plot(x2range, y1range)\n",
    "# plt.xlabel('index of data')\n",
    "# plt.ylabel('Root Mean Squared Error')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6840] 0.06917099162843145\n"
     ]
    }
   ],
   "source": [
    "m=df['valid rmse'].min()\n",
    "min_index=[i for i, j in enumerate(list(df['valid rmse'])) if j == m]\n",
    "print(min_index, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimators</th>\n",
       "      <th>max feature</th>\n",
       "      <th>max depth</th>\n",
       "      <th>min samlples leaf</th>\n",
       "      <th>training rmse</th>\n",
       "      <th>valid rmse</th>\n",
       "      <th>training r2</th>\n",
       "      <th>valid r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.044901</td>\n",
       "      <td>0.069171</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.736877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      estimators  max feature  max depth  min samlples leaf  training rmse  \\\n",
       "6840          78            2          6                  2       0.044901   \n",
       "\n",
       "      valid rmse  training r2  valid r2  \n",
       "6840    0.069171     0.905762  0.736877  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test root mean squared error :  0.07233885956086718\n"
     ]
    }
   ],
   "source": [
    "rfr=RandomForestRegressor(n_estimators=78, \n",
    "                          max_features=2,\n",
    "                          max_depth=6,\n",
    "                          max_leaf_nodes=None,\n",
    "                          min_samples_leaf=2,\n",
    "                          n_jobs=3,\n",
    "                          random_state=0)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_test_hat = rfr.predict(X_test)\n",
    "print(\"test root mean squared error : \", mean_squared_error(y_test, y_test_hat)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#피처 중요도 도표 그리기\n",
    "featureImportance = rfr.feature_importances_\n",
    " \n",
    "ynames=np.array([\"GRE Score\",\"TOEFL Score\",\"University Rating\",\"SOP\",\"LOR \",\"CGPA\",\"Research\"])\n",
    "#가장 높은 중요도 기준으로 스케일링\n",
    "featureImportance = featureImportance/featureImportance.max()\n",
    "sorted_idx = np.argsort(featureImportance)\n",
    "barPos = np.arange(sorted_idx.shape[0])+.5\n",
    "plt.barh(barPos, featureImportance[sorted_idx], align='center')\n",
    "plt.yticks(barPos, ynames[sorted_idx])\n",
    "plt.xlabel('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
